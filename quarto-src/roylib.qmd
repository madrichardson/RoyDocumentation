---
title: "Utility Library"
format: 
    html:
        theme: cosmo
        toc: true  
        toc-location: right     
        code-fold: true
        code-line-numbers: true
        css: styles.css
---

## roylib.py Library

The **roylib.py** script is a core utilities library providing array‐reshaping, authenticated file downloads, and safe file operations, plus helpers for incremental statistics (mean/count), API-driven file discovery, and CF‐compliant NetCDF generation. It also handles remote deployments via `rsync` and leap‐year checks. The script import its functions (e.g., `myReshape`, `get_netcdfFile`, `meanVar`, `makeNetcdfmDay`, `send_to_servers`) at the top of your processing scripts. `roylib.py` provides shared functions used by many of the Python scripts on saltydog.

For full details on every function in **roylib.py**, see the API reference generated by Sphinx [here](api/roylib.html).

```{python}
#| eval: false
#| code-fold: true
#| code-summary: "View roylib.py"

from __future__ import print_function
from __future__ import division
from future import standard_library

standard_library.install_aliases()
from builtins import str
from past.utils import old_div
from datetime import date, datetime, timedelta
from netCDF4 import Dataset, num2date, date2num
import numpy as np
import numpy.ma as ma
import os
import shutil
import subprocess
import time
import urllib.request, urllib.parse, urllib.error
import urllib.request, urllib.error, urllib.parse


def myReshape(dataArray):
    """
    Flatten an N-dimensional array into a 2D column vector of type float32.

    This helper is used before gridding routines that expect a single column of
    values (shape: `(n_pixels, 1)`). If `dataArray` is a `numpy.ma.MaskedArray`,
    masked entries are preserved in the output.

    Parameters
    ----------
    dataArray : numpy.ndarray or numpy.ma.MaskedArray
        Any N-dimensional array (e.g., `(n, m)`, `(n,)`, or higher rank).
        If a masked array is provided, masks are preserved in the result.

    Returns
    -------
    numpy.ma.MaskedArray or numpy.ndarray
        A 2D array of shape `(dataArray.size, 1)` with dtype `float32`.
        - If `dataArray` was a masked array, the result is a masked array.
        - Otherwise, the result is a regular `ndarray` of `float32`.
    """
    dataArray = dataArray.reshape(dataArray.size, 1)
    dataArray = np.asarray(dataArray, np.float32)
    return dataArray


def get_netcdfFile(fileName):
    """
    Download a NetCDF file from the NASA OceanColor server using wget.

    This function builds and executes a wget command that uses stored URS cookies
    for authentication. The target file is fetched from the NASA OceanColor `getfile`
    endpoint, which requires a valid URS session. The downloaded file is saved to
    the current working directory under its original name.

    Parameters
    ----------
    fileName : str
        The name of the remote NetCDF file to download (e.g.,
        `'A2023123006000.L2_LAC_SST.nc'`). This is appended to the base URL
        `https://oceandata.sci.gsfc.nasa.gov/ob/getfile/` to form the full download URL.

    Returns
    -------
    None
        This function does not return a value. On success, the file appears in the
        current directory. Existing files with the same name are overwritten.

    Raises
    ------
    RuntimeError
        If the wget command returns a non-zero exit status, indicating a download failure.
    OSError
        If the operating system command cannot be executed or if required tools are missing.
    """

    baseURL = '"https://oceandata.sci.gsfc.nasa.gov/ob/getfile/'
    wgetCommand = (
        "/usr/bin/wget -4 --load-cookies ~/.urs_cookies --save-cookies ~/.urs_cookies --auth-no-challenge=on --keep-session-cookies --content-disposition --no-check-certificate "
        + baseURL
        + fileName
        + '"'
    )
    print(wgetCommand)
    #    urllib.urlretrieve(baseURL+fileName,fileName)
    os.system(wgetCommand)


def safe_remove(fileName):
    """
    Delete a file if it exists, handling errors gracefully.

    This function checks whether the specified path refers to an existing file.
    If so, it attempts to delete it. On Windows, it waits one second after
    deletion to ensure the file handle is released. Any error during removal
    (permission denied, file in use, etc.) is caught, and the function returns
    False. Non-file paths also return False without raising.

    Parameters
    ----------
    fileName : str
        The path to the file to be removed. Can be absolute or relative.

    Returns
    -------
    bool
        True if the file existed and was removed successfully; False otherwise.
        - Returns False if the path does not point to a regular file.
        - Returns False if an exception occurs during deletion.

    Raises
    ------
    None
        All exceptions during file removal are caught; the function never raises.
    """
    try:
        if os.path.isfile(fileName):
            os.remove(fileName)
            if os.name == "nt":
                time.sleep(1)  # seconds
            return True
        else:
            return False
    except:
        return False


def send_to_servers(ncFile, dataDir, interval):
    """
    Transfer a NetCDF file to multiple remote servers via rsync and optionally copy locally.

    This function constructs an rsync command to push the specified file (`ncFile`) from
    the current working directory to two remote hosts under `/u00/satellite<remote_path>`.
    The `<remote_path>` depends on `dataDir` and `interval`. If `interval` is `"0"`, the
    remote path is `<dataDir>/<ncFile>`; otherwise it is `<dataDir><interval>day/<ncFile>`.
    After rsyncing to both servers, if `interval` equals `"1"` and `dataDir` starts with
    either `"MB"` or `"MW"`, the function also copies the file locally into the
    corresponding `/ERDData1/modisa/data/modisgf/1day/` or
    `/ERDData1/modisa/data/modiswc/1day/` directory.

    Parameters
    ----------
    ncFile : str
        The filename (with extension) of the NetCDF file to be transferred (e.g., `"A2023123006000.L2.nc"`).
    dataDir : str
        The base directory path on the remote server where the file should be placed.
        This string is used both to build the remote path and to determine local copy logic
        when `interval` is `"1"`. For example, `"/MB2023123"` or `"/MW2023123"`.
    interval : str
        The day interval specifier, typically `"0"`, `"1"`, `"3"`, etc. If `"0"`, no
        subdirectory is appended; otherwise, `<interval>day` is appended to `dataDir`
        (e.g., `"3"` → `"3day"`).

    Returns
    -------
    None
        This function does not return a value. On success, the file is transferred to
        both remote servers and possibly copied locally under `/ERDData1/modisa/...`.

    Raises
    ------
    RuntimeError
        If any rsync command returns a non-zero exit code, indicating a failure in transfer.
    OSError
        If the local file cannot be read, written, or copied (e.g., permission denied,
        path does not exist, or `shutil.copyfile` fails).
    """

    intervalDay = interval + "day"
    if interval == "0":
        remote_file = dataDir + "/" + ncFile
    else:
        remote_file = dataDir + intervalDay + "/" + ncFile
    myCmd = (
        "rsync -tvh "
        + ncFile
        + " cwatch@192.168.31.15:/u00/satellite"
        + remote_file
    )
    print(myCmd)
    os.system(myCmd)
    # myCmd = 'rsync -tvh ' + ncFile + ' cwatch@192.168.31.27:/u00/satellite' + remote_file
    # print(myCmd)
    # os.system(myCmd)
    myCmd = (
        "rsync -tvh "
        + ncFile
        + " cwatch@161.55.17.28:/u00/satellite"
        + remote_file
    )
    print(myCmd)
    os.system(myCmd)
    if (intervalDay == "1day") and (dataDir[1:3] == "MB"):
        # mvFile = '/ERDData1/modisa/data/modisgf/1day/' + ncFile
        mvFile = "/ERDData1/modisa/data/modisgf/1day/" + ncFile
        shutil.copyfile(ncFile, mvFile)
    if (intervalDay == "1day") and (dataDir[1:3] == "MW"):
        # mvFile = '/ERDData1/modisa/data/modiswc/1day/' + ncFile
        mvFile = "/ERDData1/modisa/data/modiswc/1day/" + ncFile
        shutil.copyfile(ncFile, mvFile)


def send_ncml_to_servers(ncmlFile, ncmlDir, dataDir):
    """
    Transfer a NetCDF Markup Language (NCML) file to three specified remote servers via rsync.

    This function constructs and executes three rsync commands to copy the NCML file from
    the local directory (`ncmlDir`) to each remote host under `/u00/satellite/<dataDir>`.
    The target hosts are 192.168.31.15, 192.168.31.27, and 161.55.17.28.

    Parameters
    ----------
    ncmlFile : str
        The filename of the NCML file to transfer (e.g., "example.ncml"). This file is assumed
        to reside in `ncmlDir`.
    ncmlDir : str
        Local directory path where `ncmlFile` is located.
    dataDir : str
        The target directory path (relative to `/u00/satellite/`) on each remote server.
        The full remote path becomes `/u00/satellite/<dataDir><ncmlFile>`.

    Returns
    -------
    None

    Raises
    ------
    RuntimeError
        If any rsync command returns a non-zero exit code, indicating a transfer failure.
    OSError
        If the local NCML file cannot be found or accessed, or if rsync is not available.
    """

    send_file = ncmlDir + "/" + ncmlFile
    myCmd = (
        "rsync -tvh "
        + send_file
        + " cwatch@192.168.31.15:/u00/satellite"
        + dataDir
        + ncmlFile
    )
    os.system(myCmd)
    myCmd = (
        "rsync -tvh "
        + send_file
        + " cwatch@192.168.31.27:/u00/satellite"
        + dataDir
        + ncmlFile
    )
    os.system(myCmd)
    myCmd = (
        "rsync -tvh "
        + send_file
        + " cwatch@161.55.17.28:/u00/satellite"
        + dataDir
        + ncmlFile
    )
    os.system(myCmd)


def retrieve_new_files(dataDir, param, myYear, doy, param_update_flag, lag):
    """
    Check for and download new MODIS files for a given parameter and date.

    This function constructs a search query for the NASA OceanColor file_search API
    based on the provided parameter (`"OC"` or other). It computes the calendar date
    from `myYear` and `doy`, then builds a query string of the form:
    `search=AQUA_MODIS.<YYYY><MM><DD>*L2.<param>.NRT.nc&dtype=L2&sensor=aqua&results_as_file=1`.
    It calls `url_lines1` to fetch the list of matching filenames. For each filename,
    it checks whether the file already exists in `dataDir`; if not, it sets the
    corresponding index in `param_update_flag` to True and invokes `get_netcdfFile`
    to download the missing file, pausing 20 seconds between downloads.

    Parameters
    ----------
    dataDir : str
        The directory where downloaded files should be saved (e.g., `/ERDData1/modisa/data/netcdf/`).
    param : str
        The MODIS data parameter to retrieve, typically `"OC"` (ocean color) or another dataset code.
    myYear : str
        The four-digit year (e.g., `"2023"`).
    doy : str
        The day of year as a zero-padded string (e.g., `"005"` for January 5).
    param_update_flag : list of bool
        A list of length at least 4, where `param_update_flag[lag + 3]` is set to True
        if a new file for that lag index needs to be downloaded.
    lag : int
        The offset relative to the current date, ranging from -3 to 0. This determines
        which index in `param_update_flag` to update (`lag + 3`).

    Returns
    -------
    None
        The function does not return a value. It updates `param_update_flag` in place
        and downloads any missing NetCDF files to `dataDir`.

    Raises
    ------
    urllib.error.URLError
        If the HTTP request inside `url_lines1` fails (e.g., network error).
    OSError
        If file operations (checking existence or writing) fail, or if `get_netcdfFile`
        cannot write the downloaded file.
    """

    if param == "OC":
        # modis_search_URL = 'search=A' + myYear + doy + '*L2_LAC_' + param + '.nc&dtype=L2&sensor=aqua&results_as_file=1'
        myDate = datetime(int(myYear), 1, 1) + timedelta(int(doy) - 1)
        myMonth = str(myDate.month).rjust(2, "0")
        myDay = str(myDate.day).rjust(2, "0")
        modis_search_URL = (
            "search=AQUA_MODIS."
            + myYear
            + myMonth
            + myDay
            + "*L2."
            + param
            + ".NRT.nc&dtype=L2&sensor=aqua&results_as_file=1"
        )
        print(doy)
        print(lag)
        print(modis_search_URL)
        # fileList = url_lines(modis_search_URL)
        fileList = url_lines1(modis_search_URL)
        for fName in fileList:
            fileTest = os.path.isfile(dataDir + "/" + fName)
            if not (fileTest):
                param_update_flag[lag + 3] = True
                print(fName)
                get_netcdfFile(fName)
                time.sleep(20)
    else:
        myDate = datetime(int(myYear), 1, 1) + timedelta(int(doy) - 1)
        myMonth = str(myDate.month).rjust(2, "0")
        myDay = str(myDate.day).rjust(2, "0")
        modis_search_URL = (
            "search=AQUA_MODIS."
            + myYear
            + myMonth
            + myDay
            + "*L2."
            + param
            + ".NRT.nc&dtype=L2&sensor=aqua&results_as_file=1"
        )
        print(doy)
        print(lag)
        print(modis_search_URL)
        # fileList = url_lines(modis_search_URL)
        fileList = url_lines1(modis_search_URL)
        for fName in fileList:
            fileTest = os.path.isfile(dataDir + "/" + fName)
            if not (fileTest):
                param_update_flag[lag + 3] = True
                print(fName)
                get_netcdfFile(fName)
                time.sleep(20)


def retrieve_new_files1(dataDir, param, myYear, doy, param_update_flag, lag):
    """
    Check for and download new MODIS files, handling OC and non-OC parameters differently.

    This function constructs a search query for the NASA OceanColor file_search API based on
    the given parameter. For `param == "OC"`, it uses a legacy L2_LAC endpoint; otherwise it uses
    the NRT endpoint. It computes the calendar date from `myYear` and `doy`, builds the query
    string, and retrieves the list of matching filenames via `url_lines1`. The filenames are sorted,
    and for each filename not already present in `dataDir`, it sets the corresponding index in
    `param_update_flag` to True and calls `get_netcdfFile` to download the file, pausing 20 seconds
    between downloads.

    Parameters
    ----------
    dataDir : str
        The directory where downloaded files should be saved (e.g., `/ERDData1/modisa/data/netcdf/`).
    param : str
        The MODIS data parameter to retrieve. If `"OC"`, the search endpoint uses L2_LAC_OC; otherwise
        it uses the NRT endpoint (e.g., `"SST"` or other parameter codes).
    myYear : str
        The four-digit year (e.g., `"2023"`). Used to construct the search URL.
    doy : str
        The day of year as a zero-padded string (e.g., `"005"` for January 5). Used to construct the search URL.
    param_update_flag : list of bool
        A list of length at least 4, where `param_update_flag[lag + 3]` is set to True if a new file
        needs to be downloaded for the given lag index.
    lag : int
        The offset relative to the current date, ranging from -3 to 0. Determines which index in
        `param_update_flag` to update (`lag + 3`).

    Returns
    -------
    None
        Updates `param_update_flag` in place and downloads any missing NetCDF files to `dataDir`.

    Raises
    ------
    urllib.error.URLError
        If the HTTP request inside `url_lines1` encounters a network error on all retry attempts.
    OSError
        If file operations fail (e.g., checking existence, writing to `dataDir`), or if `get_netcdfFile`
        cannot write the downloaded file.
    """
    # Rest of the code...

    if param == "OC":
        # modis_search_URL = 'search=A' + myYear + doy + '*L2_LAC_' + param + '.nc&dtype=L2&sensor=aqua&results_as_file=1'
        myDate = datetime(int(myYear), 1, 1) + timedelta(int(doy) - 1)
        myMonth = str(myDate.month).rjust(2, "0")
        myDay = str(myDate.day).rjust(2, "0")
        modis_search_URL = (
            "search=A"
            + myYear
            + doy
            + "*L2_LAC_"
            + param
            + ".nc&dtype=L2&sensor=aqua&results_as_file=1"
        )
        print(doy)
        print(lag)
        print(modis_search_URL)
        print(doy)
        print(lag)
        print(modis_search_URL)
        # fileList = url_lines(modis_search_URL)
        fileList = url_lines1(modis_search_URL)
        fileList.sort()
        for fName in fileList:
            fileTest = os.path.isfile(dataDir + "/" + fName)
            if not (fileTest):
                param_update_flag[lag + 3] = True
                print(fName)
                get_netcdfFile(fName)
                time.sleep(20)
    else:
        myDate = datetime(int(myYear), 1, 1) + timedelta(int(doy) - 1)
        myMonth = str(myDate.month).rjust(2, "0")
        myDay = str(myDate.day).rjust(2, "0")
        modis_search_URL = (
            "search=AQUA_MODIS."
            + myYear
            + myMonth
            + myDay
            + "*L2."
            + param
            + ".NRT.nc&dtype=L2&sensor=aqua&results_as_file=1"
        )
        print(doy)
        print(lag)
        print(modis_search_URL)
        # fileList = url_lines(modis_search_URL)
        fileList = url_lines1(modis_search_URL)
        fileList.sort()
        for fName in fileList:
            fileTest = os.path.isfile(dataDir + "/" + fName)
            if not (fileTest):
                param_update_flag[lag + 3] = True
                print(fName)
                get_netcdfFile(fName)
                time.sleep(20)


def isleap(year):
    """
    Determine whether the specified year is a leap year.

    This function attempts to construct a date object for February 29 of the given year.
    If the date is valid, the year is a leap year; otherwise, a ValueError is raised
    and the function returns False.

    Parameters
    ----------
    year : int
        The year to check (e.g., 2024).

    Returns
    -------
    bool
        True if `year` is a leap year (i.e., February 29 exists in that year);
        False otherwise.

    Raises
    ------
    None
        Any ValueError raised by `datetime.date(year, 2, 29)` is caught internally;
        the function never propagates exceptions.
    """

    from datetime import date, datetime, timedelta

    try:
        date(year, 2, 29)
        return True
    except ValueError:
        return False


def meanVar(mean, num, obs):
    """
    Update the running mean and count of observations with new data.

    Parameters
    ----------
    mean : numpy.ma.MaskedArray or numpy.ndarray
        The current running mean values for each element.
    num : numpy.ndarray
        The current count of valid observations for each element (integer array).
    obs : numpy.ma.MaskedArray
        The new observations with the same shape as `mean`. Masked entries are not used.

    Returns
    -------
    tuple
        A 2-tuple `(updated_mean, updated_count)` where:
        - `updated_mean` is a masked or regular array of new mean values (dtype float32).
        - `updated_count` is an integer array of updated counts (dtype int32).

    Raises
    ------
    None
        Shape mismatches or invalid operations will propagate NumPy errors.
    """

    import numpy as np
    import numpy.ma as ma

    numShape = num.shape
    temp = np.subtract(obs, mean, dtype=np.single)
    numAdd = np.ones(numShape, dtype=np.int32)
    numAdd[obs.mask] = 0
    num = np.add(num, numAdd, dtype=np.int32)
    tempNum = ma.array(num, mask=(num == 0), dtype=np.int32)
    temp = np.divide(temp, tempNum.astype("float"), dtype=np.single)
    mean = np.add(mean, temp.filled(0.0), dtype=np.single)
    return (mean, num)


def mean_sumsq(mean, ss, num, obs):
    """
    Cumulative calculation of mean and sum of squares for masked arrays.

    This function updates the running mean, sum of squares, and count of observations
    given a new set of observations. All input arrays (`mean`, `ss`, and `obs`) must be
    NumPy masked arrays of identical shape. If any input is not a masked array, the
    function exits with an error message.

    Parameters
    ----------
    mean : numpy.ma.MaskedArray
        The current running mean array. Masked entries indicate missing data and
        are not included in the update.
    ss : numpy.ma.MaskedArray
        The current running sum of squares array. Masked entries are not included
        in the update.
    num : numpy.ndarray
        The current count of valid observations for each element, as an integer array
        of the same shape as `mean`. This array is incremented for each unmasked entry
        in `obs`.
    obs : numpy.ma.MaskedArray
        The new observations to incorporate. Masked entries indicate missing data and
        are not used in updating `mean`, `ss`, or `num`.

    Returns
    -------
    tuple
        A 3-tuple `(updated_mean, updated_ss, updated_num)` where:
        - `updated_mean` (numpy.ma.MaskedArray): The updated running mean array.
        - `updated_ss` (numpy.ma.MaskedArray): The updated running sum of squares array.
        - `updated_num` (numpy.ndarray): The updated count of observations as an integer array.

    Raises
    ------
    SystemExit
        If any of `mean`, `ss`, or `obs` is not a `numpy.ma.MaskedArray`, the function
        prints an error message and exits.
    """
    import numpy as np
    import numpy.ma as ma
    import sys

    if (
        not isinstance(mean, np.ma.MaskedArray)
        or not isinstance(ss, np.ma.MaskedArray)
        or not isinstance(obs, np.ma.MaskedArray)
    ):

        print("Input arguments mean, ss, and obs are not numpy masked arrays")
        print("Try converting mean, ss, and obs to masked arrays")
        print("before using them in the function, e.g. ma.array(arg)")
        print(" ")
        sys.exit(mean_sumsq.__doc__)

    numShape = num.shape
    temp = np.subtract(obs, mean.filled(0.0), dtype=np.single)
    numAdd = np.ones(numShape, dtype=np.int32)
    numAdd[obs.mask] = 0
    num = np.add(num, numAdd, dtype=np.int32)
    tempNum = ma.array(num, mask=(num == 0), dtype=np.int32)
    print("tempNum", tempNum.min(), tempNum.max())
    tNfloat = tempNum.astype("float")

    temp = ma.divide(temp, tNfloat, dtype=np.single)
    mean = np.add(mean.filled(0.0), temp.filled(0.0), dtype=np.single)
    # mean = ma.masked_where(mean == 0., mean)

    num1 = np.copy(num)
    num2 = num1 - 1
    print("num2", num2.min(), num2.max())
    if np.any(num1 > 1):
        num1 = np.divide(num1, num2, where=(num1 > 1))

    print("num1", num1.min(), num1.max())
    print("num", num.min(), num.max())
    temp1 = ma.subtract(obs, mean, dtype=np.single)
    temp2 = np.multiply(temp1, temp1)
    print(
        "ss parts",
        ss.filled(0.0).max(),
        ma.multiply(num1, temp2).filled(0.0).max(),
    )
    ss = ss.filled(0.0) + ma.multiply(num1, temp2).filled(0.0)

    mean = ma.masked_where(num == 0, mean)
    ss = ma.masked_where(num == 0, ss)
    vr = np.divide(ss, num)
    sdev = np.sqrt(vr)
    print("stDev", sdev.min(), sdev.max(), sdev.mean())
    # print(stdev.min(), stdev.max(), stdev.mean())
    return (mean, ss, num)


def makeNetcdf(mean, nobs, interval, outFile, filesUsed, workDir):
    """
    Create a NetCDF file from aggregated data arrays and assign metadata.

    Parameters
    ----------
    mean : numpy.ma.MaskedArray or numpy.ndarray
        A 2D array of mean values (masked or regular). Masked entries are treated as missing.
    nobs : int
        The number of observations used to compute `mean`. This value is recalculated from `mean`.
    interval : int
        Time interval in days (e.g., 1, 3, 5, 8, 14). Determines which CDL template to use.
    outFile : str
        Desired output filename (e.g., '/path/to/output/MB2023123001.nc'). The function infers:
        - `dataset`: first two characters.
        - `param`: substring after the first underscore past index 10.
        - `time1` and `time2`: substrings indicating start and end DOY.
    filesUsed : list of str
        List of source filenames that contributed to `mean`. Stored in the NetCDF’s `files` attribute.
    workDir : str
        Directory in which to execute `ncgen` and write the new NetCDF file.

    Returns
    -------
    str
        The path of the generated NetCDF file (with “.nc” extension).

    Raises
    ------
    OSError
        If changing directory to `workDir` fails or if `ncgen` cannot be executed.
    RuntimeError
        If the `ncgen` command returns a non-zero exit code.
    """

    print(interval)
    os.chdir(workDir)
    now = datetime.now()
    now1 = date(now.year, now.month, now.day)
    nobs = ma.count(mean)
    noMiss = ma.count_masked(mean)
    percentCoverage = old_div(float(nobs), float(nobs + noMiss))
    # get netcdf file name and correct cdl file
    ncFile = outFile[:-3]
    dataset = outFile[0:2]
    offset = ncFile.find("_", 10)
    param = ncFile[(offset + 1) : len(ncFile)]
    time1 = outFile[2:9]
    time2 = outFile[10:17]
    ncFile = ncFile + ".nc"
    interval1 = str(interval)
    print(ncFile)
    print(dataset)
    print(param)
    print(interval1)
    # cdlFile = '/ERDData1/modisa/python/' + dataset + param + interval1 + 'Day.cdl'
    cdlFile = (
        "/ERDData1/modisa/python/" + dataset + param + interval1 + "Day.cdl"
    )
    print(cdlFile)
    # os.system('/usr/bin/ncgen -o ' + ncFile + ' ' + cdlFile)
    os.system("/usr/bin/ncgen -o " + ncFile + " " + cdlFile)
    # shutil.copyfile(cdlFile, ncFile)
    ncPointer = Dataset(ncFile, "a")
    mytime = ncPointer.variables["time"]
    ncPointer.files = filesUsed
    ncPointer.date_created = str(now1)
    ncPointer.date_issued = str(now1)
    paramName = dataset + param
    myparam = ncPointer.variables[paramName]
    tempName = myparam.long_name
    composite = "(" + interval1 + " Day Composite)"
    tempName = tempName.replace("(3 Day Composite)", composite)
    myparam.long_name = tempName
    myparam.numberOfObservations = nobs
    myparam.percentCoverage = percentCoverage
    myparam[0, 0, :, :] = mean[:, :]
    myparam.actual_range = np.array(([mean.min(), mean.max()]))
    startTimeYear = int(time1[0:4])
    startTimeDoy = int(time1[4:7])
    startDate = datetime(startTimeYear, 1, 1, 0) + timedelta(startTimeDoy - 1)
    if interval1 == "1":
        centerDate = startDate + timedelta(hours=12)
    elif interval1 == "3":
        centerDate = startDate + timedelta(hours=36)
    elif interval1 == "5":
        centerDate = startDate + timedelta(hours=60)
    elif interval1 == "8":
        centerDate = startDate + timedelta(days=4)
    elif interval1 == "14":
        centerDate = startDate + timedelta(days=7)

    udtime = date2num(centerDate, units="seconds since 1970-01-01")
    mytime[0] = udtime
    mytime.actual_range = np.array(([udtime, udtime]))
    ncPointer.close()
    return ncFile


def makeNetcdfmDay(mean, nobs, interval, outFile, filesUsed, workDir):
    """
    Create a NetCDF file for multi-day composite data.

    Parameters
    ----------
    mean : numpy.ma.MaskedArray or numpy.ndarray
        A 2D array of mean values for the composite period. Masked entries are treated as missing.
    nobs : int
        The number of observations used to compute `mean`. Recomputed internally from `mean`.
    interval : float
        The length of the composite period (in days). Used to select the “mDay” CDL template.
    outFile : str
        Desired output filename (ending in “.nc”). The function derives:
        - `dataset`: first two characters of `outFile`.
        - `param`: substring after the first underscore past index 10.
        - `time1` and `time2`: substrings for start/end DOY.
    filesUsed : list of str
        A list of source filenames that contributed to `mean`. Stored in NetCDF’s `files` attribute.
    workDir : str
        Directory in which to execute `ncgen` and write the new NetCDF file.

    Returns
    -------
    str
        The path of the generated NetCDF file (with “.nc” extension).

    Raises
    ------
    OSError
        If changing directory to `workDir` fails or if `ncgen` cannot be executed.
    RuntimeError
        If the `ncgen` command returns a non-zero exit code.
    """

    os.chdir(workDir)
    now = datetime.now()
    now1 = date(now.year, now.month, now.day)
    nobs = ma.count(mean)
    noMiss = ma.count_masked(mean)
    percentCoverage = old_div(float(nobs), float(nobs + noMiss))
    # get netcdf file name and correct cdl file
    ncFile = outFile[:-3]
    dataset = outFile[0:2]
    offset = ncFile.find("_", 10)
    param = ncFile[(offset + 1) : len(ncFile)]
    time1 = outFile[2:9]
    time2 = outFile[10:17]
    ncFile = ncFile + ".nc"
    print(ncFile)
    # cdlFile = '/ERDData1/modisa/python/' + dataset + param + 'mDay.cdl'
    cdlFile = "/ERDData1/modisa/python/" + dataset + param + "mDay.cdl"
    print(cdlFile)
    os.system("/usr/bin/ncgen -o " + ncFile + " " + cdlFile)
    # shutil.copyfile(cdlFile, ncFile)
    ncPointer = Dataset(ncFile, "a")
    mytime = ncPointer.variables["time"]
    ncPointer.files = filesUsed
    ncPointer.date_created = str(now1)
    ncPointer.date_issued = str(now1)
    paramName = dataset + param
    myparam = ncPointer.variables[paramName]
    myparam.numberOfObservations = nobs
    myparam.percentCoverage = percentCoverage
    myparam[0, 0, :, :] = mean[:, :]
    myparam.actual_range = np.array(([mean.min(), mean.max()]))
    startTimeYear = int(time1[0:4])
    startTimeDoy = int(time1[4:7])
    startDate = datetime(startTimeYear, 1, 1, 0) + timedelta(startTimeDoy - 1)
    endTimeYear = int(time2[0:4])
    endTimeDoy = int(time2[4:7])
    endDate = datetime(endTimeYear, 1, 1, 0) + timedelta(endTimeDoy - 1)
    centerDoy = old_div((startTimeDoy + endTimeDoy), 2.0)
    centerDate = datetime(startTimeYear, 1, 1, 0) + timedelta(centerDoy - 1)
    print(centerDate)
    udtime = date2num(centerDate, units="seconds since 1970-01-01")
    if (endTimeDoy - startTimeDoy + 1) == 31:
        udtime = udtime + 43200
    print(udtime)
    mytime[0] = udtime
    mytime.actual_range = np.array(([udtime, udtime]))
    ncPointer.close()
    return ncFile


def grd2netcdf(grdFile, filesUsed, fType):
    """
    Convert a GRD file to a NetCDF file, copying spatial data and metadata.

    This function reads a GRD file containing gridded data (with variables named
    either "lon"/"lat"/"z" or "x"/"y"/"z" depending on `fType`), computes coverage statistics,
    generates a NetCDF file via an `ncgen` command on a corresponding CDL template, and
    writes spatial coordinates, data values, and metadata (file list, creation date,
    observation count, coverage, and actual range) into the new NetCDF. The time variable
    is centered based on the date stamps in the original filename.

    Parameters
    ----------
    grdFile : str
        Path to the input GRD file (e.g., "/path/to/MB2023123001000.grd").
        The filename must encode the dataset, parameter, and date information:
        - The first two characters are the dataset code.
        - Characters 2-9 represent the start date (YYYYDDD).
        - Characters 10-17 represent the end date (YYYYDDD).
    filesUsed : list of str
        A list of source filenames that contributed to the GRD data. This list is stored
        in the NetCDF file's `files` attribute.
    fType : str
        File type indicator:
        - `"MW"` uses variables `"lon"`, `"lat"`, and `"z"`.
        - Any other value uses variables `"x"`, `"y"`, and `"z"`.

    Returns
    -------
    str
        The path of the generated NetCDF file (same as `grdFile` with a “.nc” extension).

    Raises
    ------
    OSError
        If reading the GRD file or executing the `ncgen` command fails (e.g., file not found,
        permission denied).
    RuntimeError
        If the `ncgen` command returns a non-zero exit code, indicating failure to generate
        the NetCDF file.
    """

    now = datetime.now()
    now1 = date(now.year, now.month, now.day)
    grdPointer = Dataset(grdFile)
    if fType == "MW":
        x = grdPointer.variables["lon"][:]
        y = grdPointer.variables["lat"][:]
        z = grdPointer.variables["z"][:, :]
    else:
        x = grdPointer.variables["x"][:]
        y = grdPointer.variables["y"][:]
        z = grdPointer.variables["z"][:, :]
    grdPointer.close()
    nobs = ma.count(z)
    noMiss = ma.count_masked(z)
    percentCoverage = old_div(float(nobs), float(nobs + noMiss))
    # get netcdf file name and correct cdl file
    ncFile = grdFile[:-4]
    dataset = grdFile[0:2]
    offset = ncFile.find("_", 10)
    param = ncFile[(offset + 1) : len(ncFile)]
    time1 = grdFile[2:9]
    time2 = grdFile[10:17]
    interval = str(int(time2) - int(time1) + 1)
    ncFile = ncFile + ".nc"
    print(ncFile)
    # cdlFile = '/ERDData1/modisa/python/' + dataset + param + interval + 'Day.cdl'
    cdlFile = (
        "/ERDData1/modisa/python/" + dataset + param + interval + "Day.cdl"
    )
    print(cdlFile)
    os.system("/usr/bin/ncgen -o " + ncFile + " " + cdlFile)
    # shutil.copyfile(cdlFile, ncFile)
    ncPointer = Dataset(ncFile, "a")
    lat = ncPointer.variables["lat"]
    lon = ncPointer.variables["lon"]
    mytime = ncPointer.variables["time"]
    ncPointer.files = filesUsed
    ncPointer.date_created = str(now1)
    ncPointer.date_issued = str(now1)
    paramName = dataset + param
    myparam = ncPointer.variables[paramName]
    lat[:] = y[:]
    lon[:] = x[:]
    myparam[0, 0, :, :] = z[:, :]
    myparam.numberOfObservations = nobs
    myparam.percentCoverage = percentCoverage
    myparam.actual_range = np.array(([z.min(), z.max()]))
    startTimeYear = int(time1[0:4])
    startTimeDoy = int(time1[4:7])
    startDate = datetime(startTimeYear, 1, 1, 0) + timedelta(startTimeDoy - 1)
    if interval == "1":
        centerDate = startDate + timedelta(hours=12)
    elif interval == "3":
        centerDate = startDate + timedelta(hours=36)
    elif interval == "5":
        centerDate = startDate + timedelta(hours=60)
    elif interval == "8":
        centerDate = startDate + timedelta(days=4)
    elif interval == "14":
        centerDate = startDate + timedelta(days=7)

    udtime = date2num(centerDate, units="seconds since 1970-01-01")
    mytime[0] = udtime
    mytime.actual_range = np.array(([udtime, udtime]))
    ncPointer.close()
    return ncFile


def grd2netcdf1(grdFile, fileOut, filesUsed, my_mask, fType):
    """
    Convert an Xarray grid file to a NetCDF file, applying a land mask and writing metadata.

    Parameters
    ----------
    grdFile : xarray.Dataset
        The input grid dataset. If `fType == "MW"`, it must have `.lon`, `.lat`, and `.values`.
        Otherwise, it must have `.x`, `.y`, and `.values`.
    fileOut : str
        The target output filename (e.g., '/path/to/output/MB2023123001.nc'). The function
        derives dataset, parameter, start/end DOY from this name.
    filesUsed : list of str
        A list of source filenames that contributed to the grid; stored in the NetCDF's `files`.
    my_mask : numpy.ndarray
        A boolean or integer mask array of the same shape as `grdFile.values`. Points where
        `my_mask != 1` are set to NaN and then masked.
    fType : str
        File type indicator:
        - `"MW"` → use `grdFile.lon.values`, `grdFile.lat.values`, and `grdFile.values`.
        - Any other string → use `grdFile.x.values`, `grdFile.y.values`, and `grdFile.values`.

    Returns
    -------
    str
        The path of the generated NetCDF file (same as `fileOut` with “.nc” extension).

    Raises
    ------
    OSError
        If the GRD file cannot be read or if the `ncgen` command fails to run.
    RuntimeError
        If `ncgen` returns a non-zero exit code.
    """

    from datetime import datetime, timedelta
    from netCDF4 import Dataset
    import xarray as xr

    now = datetime.now()
    now1 = date(now.year, now.month, now.day)
    if fType == "MW":
        x = grdFile.lon.values
        y = grdFile.lat.values
        z = grdFile.values
    else:
        x = grdFile.x.values
        y = grdFile.y.values
        z = grdFile.values

    # set areas in land mask not land to NaN
    z[my_mask != 1] = np.NAN
    # convert z to ma.array with NaNs masked
    z = ma.array(z, mask=np.isnan(z), fill_value=-9999999.0)
    nobs = ma.count(z)
    noMiss = ma.count_masked(z)
    percentCoverage = old_div(float(nobs), float(nobs + noMiss))
    # get netcdf file name and correct cdl file
    ncFile = fileOut[:-4]
    dataset = fileOut[0:2]
    offset = ncFile.find("_", 10)
    param = ncFile[(offset + 1) : len(ncFile)]
    time1 = fileOut[2:9]
    time2 = fileOut[10:17]
    interval = str(int(time2) - int(time1) + 1)
    ncFile = ncFile + ".nc"
    print(ncFile)
    # cdlFile = '/ERDData1/modisa/python/' + dataset + param + interval + 'Day.cdl'
    cdlFile = (
        "/ERDData1/modisa/python/" + dataset + param + interval + "Day.cdl"
    )
    print(cdlFile)
    os.system("/usr/bin/ncgen -o " + ncFile + " " + cdlFile)
    # shutil.copyfile(cdlFile, ncFile)
    ncPointer = Dataset(ncFile, "a")
    lat = ncPointer.variables["lat"]
    lon = ncPointer.variables["lon"]
    mytime = ncPointer.variables["time"]
    ncPointer.files = filesUsed
    ncPointer.date_created = str(now1)
    ncPointer.date_issued = str(now1)
    paramName = dataset + param
    myparam = ncPointer.variables[paramName]
    lat[:] = y[:]
    lon[:] = x[:]
    myparam[0, 0, :, :] = z[:, :]
    myparam.numberOfObservations = nobs
    myparam.percentCoverage = percentCoverage
    myparam.actual_range = np.array(([z.min(), z.max()]))
    startTimeYear = int(time1[0:4])
    startTimeDoy = int(time1[4:7])
    startDate = datetime(startTimeYear, 1, 1, 0) + timedelta(startTimeDoy - 1)
    if interval == "1":
        centerDate = startDate + timedelta(hours=12)
    elif interval == "3":
        centerDate = startDate + timedelta(hours=36)
    elif interval == "5":
        centerDate = startDate + timedelta(hours=60)
    elif interval == "8":
        centerDate = startDate + timedelta(days=4)
    elif interval == "14":
        centerDate = startDate + timedelta(days=7)

    udtime = date2num(centerDate, units="seconds since 1970-01-01")
    mytime[0] = udtime
    mytime.actual_range = np.array(([udtime, udtime]))
    ncPointer.close()
    return ncFile


def update_modis_1day(now, basedataDir, param, param_update_flag):
    """
    Execute daily MODIS processing scripts for SST or Chla based on update flags.

    This function iterates over the three most recent lags (-3, -2, -1 days relative to `now`).
    For each lag where `param_update_flag[lag + 3]` is True, it computes the corresponding date,
    constructs the directory path under `basedataDir`, and invokes the appropriate daily processing
    scripts via `os.system`. For `"SST"`, it runs both `makeSST1daynewMW.py` and `makeSST1daynewMB.py`;
    for `"Chla"`, it runs both `makeChla1daynewMW.py` and `makeChla1daynewMB.py`. Each script is
    passed the year and day-of-year strings as arguments.

    Parameters
    ----------
    now : datetime.datetime
        The reference datetime (typically the current date and time). Used to compute the target date
        for each lag.
    basedataDir : str
        The base path for data directories (e.g., "/ERDData1/modisa/data/netcdf/"). For each lag,
        the function will append `<YYYY><MM>` to this path to form `dataDir`.
    param : str
        The parameter to process: either `"SST"` or `"Chla"`. Determines which pair of scripts to invoke.
    param_update_flag : list of bool
        A list of length at least 4. For each `lag` in `[-3, -2, -1]`, if `param_update_flag[lag + 3]`
        is True, the function will trigger processing for that lag index.

    Returns
    -------
    None
        This function does not return a value. It updates no in-memory state beyond side effects
        of calling external scripts.

    Raises
    ------
    OSError
        If the working directory or the external processing scripts cannot be invoked (e.g., path not found,
        permission denied). Any non-zero exit code from `os.system` is not captured but may indicate failure.
    """

    for lag in list(range(-3, 0)):
        if param_update_flag[lag + 3]:
            myDate1 = now + timedelta(days=lag)
            myYear = str(myDate1.year)
            myMon = str(myDate1.month)
            myMon = myMon.rjust(2, "0")
            doy = myDate1.strftime("%j").zfill(3)
            dataDir = basedataDir + myYear + myMon
            if param == "SST":
                # myCmd = '/home/cwatch/anaconda3/bin/python /home/cwatch/newPython/modisa/makeSST1daynewMW.py  /ERDData1/modisa/data/netcdf/ /ERDData1/modisa/work/ ' + myYear + ' ' + doy
                myCmd = (
                    "/home/cwatch/mambaforge/bin/python /home/cwatch/newPython/modisa/makeSST1daynewMW.py  /ERDData1/modisa/data/netcdf/ /ERDData1/modisa/work/ "
                    + myYear
                    + " "
                    + doy
                )
                os.system(myCmd)
                # myCmd = '/home/cwatch/anaconda3/bin/python /home/cwatch/newPython/modisa/makeSST1daynewMB.py  /ERDData1/modisa/data/netcdf/ /ERDData1/modisa/work1/ ' + myYear + ' ' + doy
                myCmd = (
                    "/home/cwatch/mambaforge/bin/python /home/cwatch/newPython/modisa/makeSST1daynewMB.py  /ERDData1/modisa/data/netcdf/ /ERDData1/modisa/work1/ "
                    + myYear
                    + " "
                    + doy
                )
                os.system(myCmd)
            else:
                # myCmd = '/home/cwatch/anaconda3/bin/python /home/cwatch/newPython/modisa/makeChla1daynewMW.py /ERDData1/modisa/data/netcdf/ /ERDData1/modisa/work/ ' + myYear + ' ' + doy
                myCmd = (
                    "/home/cwatch/mambaforge/bin/python /home/cwatch/newPython/modisa/makeChla1daynewMW.py /ERDData1/modisa/data/netcdf/ /ERDData1/modisa/work/ "
                    + myYear
                    + " "
                    + doy
                )
                os.system(myCmd)
                # myCmd = '/home/cwatch/anaconda3/bin/python /home/cwatch/newPython/modisa/makeChla1daynewMB.py  /ERDData1/modisa/data/netcdf/ /ERDData1/modisa/work1/ ' + myYear + ' ' + doy
                myCmd = (
                    "/home/cwatch/mambaforge/bin/python /home/cwatch/newPython/modisa/makeChla1daynewMB.py  /ERDData1/modisa/data/netcdf/ /ERDData1/modisa/work1/ "
                    + myYear
                    + " "
                    + doy
                )
                os.system(myCmd)


def update_modis_composite(
    now, basedataDir, param, param_update_flag, composite
):
    """
    Update MODIS composite products for specified date lags and parameter.

    This function iterates over the three days immediately preceding `now` (lags -3, -2, -1).
    For each lag, it computes the corresponding date, builds the data directory path from
    `basedataDir`, and checks if any daily updates occurred in that range by summing the
    boolean flags in `param_update_flag` up to the current lag index. If an update is needed,
    it invokes the appropriate composite scripts via `os.system`. When `param` is `'SST'`,
    it runs `CompMBSST.py` and `CompMWSST.py`; when `param` is `'Chla'`, it runs
    `CompMBChla.py` and `CompMWChla.py`. Each script is passed the year, day-of-year, and
    the `composite` interval as command-line arguments.

    Parameters
    ----------
    now : datetime.datetime
        The reference datetime used to calculate the target dates for each lag.
    basedataDir : str
        The base path where daily composite input data resides (e.g.,
        '/ERDData1/modisa/data/modisgf/1day/').
    param : str
        The parameter type to process: either `'SST'` or `'Chla'`.
    param_update_flag : list of bool
        A list of length at least 4. For each lag in [-3, -2, -1], if the sum of
        `param_update_flag[0]` through `param_update_flag[lag + 3]` is greater than zero,
        the composite update scripts will be invoked for that lag.
    composite : str
        The composite interval identifier (e.g., `'3'`, `'5'`, `'8'`, `'14'`). Passed to
        external scripts to control the composite period.

    Returns
    -------
    None
        This function does not return a value. It performs side effects by calling
        external composite scripts.

    Raises
    ------
    OSError
        If any of the external composite scripts cannot be executed (e.g., the script
        file is missing or not executable).
    """

    for lag in list(range(-3, 0)):
        myDate1 = now + timedelta(days=lag)
        myYear = str(myDate1.year)
        myMon = str(myDate1.month)
        myMon = myMon.rjust(2, "0")
        doy = myDate1.strftime("%j").zfill(3)
        dataDir = basedataDir + myYear + myMon
        temp = param_update_flag[0 : (lag + 4)]
        if sum(temp) > 0:
            if param == "SST":
                # myCmd = '/home/cwatch/anaconda3/bin/python /home/cwatch/newPython/modisa/CompMBSST.py /ERDData1/modisa/data/modisgf/1day/ /ERDData1/modisa/work1/ ' + myYear + ' ' + doy + ' ' + composite
                myCmd = (
                    "/home/cwatch/anaconda3/bin/python /home/cwatch/newPython/modisa/CompMBSST.py /ERDData1/modisa/data/modisgf/1day/ /ERDData1/modisa/work1/ "
                    + myYear
                    + " "
                    + doy
                    + " "
                    + composite
                )
                os.system(myCmd)
                # myCmd = '/home/cwatch/anaconda3/bin/python /home/cwatch/newPython/modisa/CompMWSST.py /ERDData1/modisa/data/modiswc/1day/ /ERDData1/modisa/work/ ' + myYear + ' ' + doy + ' ' + composite
                myCmd = (
                    "/home/cwatch/anaconda3/bin/python /home/cwatch/newPython/modisa/CompMWSST.py /ERDData1/modisa/data/modiswc/1day/ /ERDData1/modisa/work/ "
                    + myYear
                    + " "
                    + doy
                    + " "
                    + composite
                )
                os.system(myCmd)
            else:
                # myCmd = '/home/cwatch/anaconda3/bin/python /home/cwatch/newPython/modisa/CompMBChla.py /ERDData1/modisa/data/modisgf/1day/ /ERDData1/modisa/work1/ ' + myYear + ' ' + doy + ' ' + composite
                myCmd = (
                    "/home/cwatch/anaconda3/bin/python /home/cwatch/newPython/modisa/CompMBChla.py /ERDData1/modisa/data/modisgf/1day/ /ERDData1/modisa/work1/ "
                    + myYear
                    + " "
                    + doy
                    + " "
                    + composite
                )
                os.system(myCmd)
                # myCmd = '/home/cwatch/anaconda3/bin/python /home/cwatch/newPython/modisa/CompMWChla.py /ERDData1/modisa/data/modiswc/1day/ /ERDData1/modisa/work/ ' + myYear + ' ' + doy + ' ' + composite
                myCmd = (
                    "/home/cwatch/anaconda3/bin/python /home/cwatch/newPython/modisa/CompMWChla.py /ERDData1/modisa/data/modiswc/1day/ /ERDData1/modisa/work/ "
                    + myYear
                    + " "
                    + doy
                    + " "
                    + composite
                )
                os.system(myCmd)


def url_lines(url):
    """
    Download a file from a URL via `wget` and return its lines.

    This function constructs a `wget` command to fetch the content at the
    specified URL, saves it to a temporary files, retries up to 24 times
    if the download yields an empty file, and then returns the file's lines
    as a list of strings (with trailing newline characters stripped).

    Parameters
    ----------
    url: str
        The query string or full URL to pass to the NASA OceanData
        file_search API via `wget`. This should include any necessary
        parameters (e.g. `?dataset=...&time_min=...`).

    Returns
    -------
    str
        A list of lines (`str`) read from the downloaded file. Each
        element has had its trailing newline removed.

    Raises
    ------
    RuntimeError
        If the file remains empty after the maximum number of retries.
    FileNotFoundError
        If the downloaded file cannot be opened.
    OSError
        If an underlying OS call fails (e.g., `wget` not found, permission
        issues, etc.).
    subprocess.CalledProcessError
        If `wget` exits with a non-zero status (when called with
        `check=True`).
    """

    # Initialize an empty list to store the lines read from the downloaded file
    myList = []

    print(url)

    # Initialize retry counter
    no_tries = 1

    # Attempt up to 24 additional downloads (total 24 tries) until the file in non-empty
    while no_tries < 25:

        # Build the wget command to fetch data from the NASA OceanData API,
        # saving output to a temporary file
        wgetCmd = "/usr/bin/wget -O /home/cwatch/newPython/modisa/fileNames.txt --no-check-certificate 'https://oceandata.sci.gsfc.nasa.gov/api/file_search?" + url + "'"
        # Print the command for debugging purposes
        print(wgetCmd)

        # Execute the command in a subshell; capture the return code
        returnCode = subprocess.call(wgetCmd, shell = True)
        print('return code: ' + str(returnCode))
        
        # Check size of the downloaded file
        file_size = os.path.getsize('/home/cwatch/newPython/modisa/fileNames.txt')
        print('search file size: ' + str(file_size))

        # If the file has content, break out of the retry loop
        if (file_size > 0):
            break
        else:
            # Otherwise, increment retry counter and wait before trying
            no_tries = no_tries + 1
            time.sleep(5)

    # Open the downloaded file for reading       
    f = open('/home/cwatch/newPython/modisa/fileNames.txt', 'r')

    # iterate over each line in the file
    for line in f:
        # Strip trailing newline/carriage-return and append to our list
        myList.append(line.rstrip())

    # Close the file to free up resources
    f.close()

    # Print the first two entries for a quick preview
    print('myList: ' + str(myList[0:2]))

    # Return the full list of lines
    return myList


def url_lines1(url):
    """
    Fetch a list of file names from the NASA OceanData API.

    This function constructs a full API request URL by appending the
    provided query string to the OceanData file_search endpoint, then
    attempts up to 24 retries (with a 5-second delay) to fetch the
    response. Once a non-empty response is received, it decodes each
    line as UTF-8, strips trailing whitespace, and returns the lines
    as a list of strings.

    Parameters
    ----------
    url: str
        A query string containing one or more URL-encoded parameters
        (e.g. `"dataset=MODISA_L2&time_min=2025-06-01&time_max=2025-06-10"`).

    Returns
    -------
    str
        A list of decoded, stripped lines from the API response.

    Raises
    ------
    urllib.error.URLError
        If there is a network problem or the URL cannot be reached.
    urllib.error.HTTPError
        If the server returns an HTTP error status (e.g., 404 or 500).
    RuntimeError
        If no data is returned after 24 retries.
    """

    # Initialize empty list to collect decoded lines from the response
    myList = []

    print(url)

    # Construct the full API endpoint URL by prefixing the base endpoint
    url_new = 'https://oceandata.sci.gsfc.nasa.gov/api/file_search?' +  url
    print(url_new)

    # Initialize a retry counter; we will attempt up to 24 additional tries
    no_tries = 1

    # Loop until we either get data or exceed the retry limit
    while no_tries < 25:
        # Open the URL and read all lines from the HTTP response
        with urllib.request.urlopen(url_new) as response:
            flist = response.readlines()

        # Log how many lines were returned in the attempt
        print('filelist length: ' + str(len(flist)))

        # If we recieved at least one line, break out of the retry loop
        if (len(flist) > 0):
            break
        else:
            # Otherwise, increment retry counter and pause before retrying
            no_tries = no_tries + 1
            time.sleep(5)

    # Iterate over each raw byte line in the response list
    for line in flist:
        # Decode bytes to a UTF-8 string
        junk = line.decode('UTF-8')
        # Strip any trailing whitespace or newline characters and append to our list
        myList.append(junk.rstrip())
    
    # Return the list of cleaned, decoded lines
    return myList

```